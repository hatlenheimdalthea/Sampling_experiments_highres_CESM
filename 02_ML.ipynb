{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4647fbee-e926-411f-b0b1-4c8910a09fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 23:48:13.046512: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-23 23:48:13.061398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 23:48:13.079760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 23:48:13.085111: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 23:48:13.098800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "import joblib\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import sklearn           \n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb     \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import mCDR_utils as prerun\n",
    "\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a8f3e2-b042-4a95-8f3f-7955f777f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = 'nmse' \n",
    "#approach = 'bias' \n",
    "\n",
    "recon_output_dir = 'gs://leap-persistent/your_username'\n",
    "hyperparam_dir = 'gs://leap-persistent/your_username'\n",
    "ml_model_save_path = '/home/jovyan/mCDR'\n",
    "path_seeds = 'gs://leap-persistent/abbysh/pickles/random_seeds.npy'\n",
    "\n",
    "jobs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff175c2-e2a2-4de0-978d-1bba540aa793",
   "metadata": {},
   "source": [
    "# For bias as hyperparameter error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee43512-99bd-43dc-9964-1d9e1d90e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_fxn(truth,pred):\n",
    "    bias = pred - truth\n",
    "    return np.abs(np.nanmean(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa632a9e-abd0-4409-aaf5-8528f4935044",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_scorer = make_scorer(bias_fxn, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56782d8a-ae1b-4dc9-9afb-7c95706c6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open('gs://leap-persistent/abbysh/pickles/random_seeds.npy') as pam:\n",
    "     random_seeds = np.load(pam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b813e1fe-82ac-42ca-9c5f-fed6964cdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_start = '2020-02-01T00:00:00.000000000'\n",
    "date_range_end = '2022-01-01T00:00:00.000000000'\n",
    "\n",
    "dates = pd.date_range(start=date_range_start, \n",
    "                      end=date_range_end,freq='MS') + np.timedelta64(14, 'D')\n",
    "\n",
    "init_date = str(dates[0].year) + format(dates[0].month,'02d')\n",
    "fin_date = str(dates[-1].year) + format(dates[-1].month,'02d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af349ebc-d729-4884-8f30-98faeb3ed094",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prop = .2\n",
    "test_prop = .2\n",
    "\n",
    "\n",
    "# xg_param_grid = {\"n_estimators\":[500, 1000, 2000, 4000],\n",
    "#                  \"max_depth\":[5, 10, 15],\n",
    "#                  \"learning_rate\":[0.10, 0.30, 0.40]\n",
    "#                 }\n",
    "\n",
    "best_params = {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 4000}\n",
    "\n",
    "# Results from previous bias grid search\n",
    "#best_params = {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 2000}\n",
    "\n",
    "\n",
    "features_sel = ['sst','sst_anom','sss','sss_anom','mld_clim_log','chl_log','chl_log_anom','xco2','A', 'B', 'C', 'T0', 'T1'] \n",
    "target_sel = ['pco2_residual'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efeb1e6-3133-4357-8558-500ed254063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_dates = []\n",
    "test_dates = []\n",
    "\n",
    "for i in range(0,len(dates)):\n",
    "    \n",
    "    if i % 5 != 0:\n",
    "        select_dates.append(dates[i]) \n",
    "    if i % 5 == 0:\n",
    "        test_dates.append(dates[i]) \n",
    "        \n",
    "\n",
    "year_mon = []\n",
    "\n",
    "for i in range(0,len(select_dates)):\n",
    "    \n",
    "    tmp = select_dates[i]\n",
    "    year_mon.append(f\"{tmp.year}-{tmp.month}\")\n",
    "    \n",
    "test_year_mon = []\n",
    "\n",
    "for i in range(0,len(test_dates)):\n",
    "    \n",
    "    tmp = test_dates[i]\n",
    "    test_year_mon.append(f\"{tmp.year}-{tmp.month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9a2539-d618-4ead-8788-ca52b05fe164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-23 23:48:28.819155\n",
      "481939\n",
      "120159\n",
      "Starting model saving process\n",
      "Save complete\n",
      "test performance metrics: {'mse': 243.11351013183594, 'mae': 10.761034965515137, 'medae': 7.1709595, 'max_error': 92.95462, 'bias': 4.045164, 'r2': 0.8906974792480469, 'corr': 0.9542875391108607, 'cent_rmse': 15.058226080380626, 'stdev': 50.301888, 'amp_ratio': 0.9910926, 'stdev_ref': 47.161705, 'range_ref': 330.80823, 'iqr_ref': 74.75595092773438}\n",
      "unseen performance metrics: {'mse': 2197.632080078125, 'mae': 35.79771041870117, 'medae': 27.717058, 'max_error': 331.72897, 'bias': -3.0952494, 'r2': -2.0441248416900635, 'corr': 0.17478747793176985, 'cent_rmse': 46.77657530691109, 'stdev': 43.273197, 'amp_ratio': 0.74493426, 'stdev_ref': 26.868677, 'range_ref': 499.95062, 'iqr_ref': 23.909423828125}\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/abbysh/ncar_files/post02_xgb_output/0022_north/reconstructions/recon_fC02residual_nmse_mon_01x01_202002_202201.zarr\n",
      "Save complete\n",
      "end of all members 2025-04-24 00:28:27.177717\n",
      "saving performance metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "K_folds = 3\n",
    "first_mem = False # Change to true if applying grid search\n",
    "\n",
    "metrics_output_dir = '/home/jovyan/mCDR'\n",
    "\n",
    "test_perform_fname = f\"{metrics_output_dir}/{approach}_test_performance_2020-2022.csv\"\n",
    "unseen_perform_fname = f\"{metrics_output_dir}/{approach}_unseen_performance_2020-2022.csv\"\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "\n",
    "file_path = 'gs://leap-persistent/abbysh/ncar_files/post01_xgb_inputs/0022_north/MLinput_CESM_mon_.1x.1_202002_202201.pkl'\n",
    "      \n",
    "with fs.open(file_path,'rb') as filee:\n",
    "    df = pd.read_pickle(filee)\n",
    "    df['year'] = df.index.get_level_values('time').year\n",
    "    df['mon'] = df.index.get_level_values('time').month\n",
    "    df['year_month'] = df['year'].astype(str) + \"-\" + df['mon'].astype(str)\n",
    "    recon_sel = (~df[features_sel+target_sel].isna().any(axis=1)) & ((df[target_sel] < 250) & (df[target_sel] > -250)).to_numpy().ravel()\n",
    "\n",
    "    sel = (recon_sel & ((df['socat_mask'] == 1)))\n",
    "    train_sel = (sel & (pd.Series(df['year_month']).isin(year_mon))).to_numpy().ravel()\n",
    "    print(sum(train_sel)) \n",
    "\n",
    "    test_sel = (sel & (pd.Series(df['year_month']).isin(test_year_mon))).to_numpy().ravel()\n",
    "    print(sum(test_sel))\n",
    "    unseen_sel = (recon_sel & (df['socat_mask'] == 0))\n",
    "\n",
    "    X = df.loc[sel,features_sel].to_numpy()\n",
    "    y = df.loc[sel,target_sel].to_numpy().ravel()\n",
    "         \n",
    "    Xtrain = df.loc[train_sel,features_sel].to_numpy()             \n",
    "    ytrain = df.loc[train_sel,target_sel].to_numpy().ravel()\n",
    "\n",
    "    N = Xtrain.shape[0]\n",
    "    train_val_idx, train_idx, val_idx, test_idx = prerun.train_val_test_split(N, test_prop, val_prop, random_seeds, seed_loc)\n",
    "    X_train_val, X_train, X_val, X_test_tmp, y_train_val, y_train, y_val, y_test_tmp = prerun.apply_splits(Xtrain, ytrain, train_val_idx, train_idx, val_idx, test_idx) \n",
    "\n",
    "    X_test = df.loc[test_sel,features_sel].to_numpy()                \n",
    "    y_test = df.loc[test_sel,target_sel].to_numpy().ravel()    \n",
    "   \n",
    "    if first_mem:\n",
    "        model = XGBRegressor(random_state=random_seeds[4,seed_loc], n_jobs=jobs)\n",
    "        param_grid = xg_param_grid\n",
    "        if approach == 'bias':\n",
    "            grid = GridSearchCV(model, param_grid, scoring=bias_scorer, cv=K_folds, return_train_score=True, refit=False, \n",
    "                            verbose=3)\n",
    "        elif approach == 'nmse':\n",
    "            grid = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=K_folds, return_train_score=True, refit=False, \n",
    "                            verbose=3)\n",
    "        print(grid)\n",
    "        grid.fit(X_train_val, y_train_val)\n",
    "        best_params = grid.best_params_\n",
    "        print(best_params)\n",
    "        scores = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "        scores.to_csv(f'{hyperparam_dir}/CVgrid_scores_{approach}.csv')\n",
    "    \n",
    "    train_performance = defaultdict(dict)\n",
    "    test_performance = defaultdict(dict)\n",
    "    unseen_performance = defaultdict(dict)\n",
    "\n",
    "    model = XGBRegressor(random_state=random_seeds[5,seed_loc], **best_params, n_jobs=jobs)\n",
    "    model.fit(X_train_val, y_train_val)          \n",
    "\n",
    "    prerun.save_model(model, dates, ml_model_save_path, approach)   \n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_performance = prerun.evaluate_test(y_test, y_pred_test)\n",
    "    \n",
    "    fields = test_performance.keys()\n",
    "    test_row_dict = dict()\n",
    "    \n",
    "    for field in fields:\n",
    "        test_row_dict[field] = test_performance[field]\n",
    "\n",
    "    file_exists = os.path.isfile(test_perform_fname)\n",
    "    \n",
    "    with open(test_perform_fname, 'a') as f_object:\n",
    "        writer = csv.DictWriter(f_object, fieldnames = test_row_dict.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader() \n",
    "        writer.writerow(test_row_dict)\n",
    "        \n",
    "    print('test performance metrics:', test_performance)\n",
    "\n",
    "\n",
    "    y_pred_unseen = model.predict(df.loc[unseen_sel,features_sel].to_numpy())\n",
    "    y_unseen = df.loc[unseen_sel,target_sel].to_numpy().ravel()\n",
    "    unseen_performance = prerun.evaluate_test(y_unseen, y_pred_unseen)\n",
    "    \n",
    "    fields = unseen_performance.keys()\n",
    "    unseen_row_dict = dict()\n",
    "    \n",
    "    for field in fields:\n",
    "        unseen_row_dict[field] = unseen_performance[field]\n",
    "\n",
    "    file_exists = os.path.isfile(unseen_perform_fname)\n",
    "    \n",
    "    with open(unseen_perform_fname, 'a') as f_object:\n",
    "        writer = csv.DictWriter(f_object, fieldnames = unseen_row_dict.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader() \n",
    "        writer.writerow(unseen_row_dict)\n",
    "    \n",
    "    print('unseen performance metrics:', unseen_performance)\n",
    "\n",
    "    y_pred_seen = model.predict(X)\n",
    "\n",
    "    df['pco2_residual_full_recon'] = np.nan\n",
    "    df.loc[unseen_sel,['pco2_residual_full_recon']] = y_pred_unseen   \n",
    "    df.loc[sel,['pco2_residual_full_recon']] = y_pred_seen\n",
    "    \n",
    "    df['pco2_residual_test'] = np.nan\n",
    "    df.loc[unseen_sel,['pco2_residual_test']] = np.nan\n",
    "    df.loc[sel,['pco2_residual_test']] = y_pred_seen\n",
    "    df.loc[train_sel, ['pco2_residual_test']] = np.nan\n",
    "\n",
    "    df['pco2_residual_train'] = np.nan\n",
    "    df.loc[unseen_sel,['pco2_residual_train']] = np.nan\n",
    "    df.loc[sel,['pco2_residual_train']] = y_pred_seen\n",
    "    df.loc[test_sel, ['pco2_residual_train']] = np.nan\n",
    "\n",
    "    df['pco2_residual_unseen'] = np.nan\n",
    "    df.loc[unseen_sel,['pco2_residual_unseen']] = y_pred_unseen\n",
    "    df.loc[sel,['pco2_residual_unseen']] = np.nan\n",
    "\n",
    "    df['pco2_residual_seen'] = np.nan\n",
    "    df.loc[unseen_sel,['pco2_residual_seen']] = np.nan\n",
    "    df.loc[sel,['pco2_residual_seen']] = y_pred_seen\n",
    "\n",
    "    DS_recon = df[['socat_mask','pco2_residual','pco2_residual_full_recon','pco2_residual_seen','pco2_residual_unseen', 'pco2_residual_test', 'pco2_residual_train']].to_xarray()\n",
    "\n",
    "    prerun.save_recon(DS_recon, dates, recon_output_dir, approach)   \n",
    "            \n",
    "print('end of all members', datetime.datetime.now())\n",
    "print('saving performance metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea609ae-2c72-43cb-be69-361e8f2e7d59",
   "metadata": {},
   "source": [
    "## Add pCO2-T back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb97440-af1f-4f98-8471-fa0a1c01a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded_members_dir = 'gs://leap-persistent/abbysh/ncar_files/processed'\n",
    "fco2_recon_dir = 'gs://leap-persistent/your_username'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedefe1e-86c2-49e9-b02f-c75f03943a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recon_fco2(regridded_members_dir, fco2_recon_dir):\n",
    "    \n",
    "    fco2T_path = f'{regridded_members_dir}/pco2_components_202002-202201.zarr'\n",
    "    print('fco2T path:',fco2T_path)            \n",
    "    fco2D_path = f\"{fco2_recon_dir}/recon_fC02residual_nmse_mon_01x01_202002_202201.zarr\"\n",
    "    print('fco2D path:',fco2D_path)\n",
    "    file_out = f\"{fco2_recon_dir}/recon_pCO2_nmse_mon_01x01_202002-202201.zarr\" \n",
    "    print('save path:',file_out)\n",
    "\n",
    "    fco2T_series = xr.open_dataset(fco2T_path,engine='zarr').pco2_T.transpose(\"time\",\"latitude\",\"longitude\") \n",
    "    \n",
    "    fco2_ml_output = xr.open_dataset(fco2D_path,engine='zarr')\n",
    "    \n",
    "    fco2D_unseen_series = fco2_ml_output.pco2_residual_unseen.transpose(\"time\",\"latitude\",\"longitude\") \n",
    "    fco2D_full_series = fco2_ml_output.pco2_residual_full_recon.transpose(\"time\",\"latitude\",\"longitude\") \n",
    "    fco2D_train_series = fco2_ml_output.pco2_residual_train.transpose(\"time\",\"latitude\",\"longitude\") \n",
    "    fco2D_test_series = fco2_ml_output.pco2_residual_test.transpose(\"time\",\"latitude\",\"longitude\") \n",
    "\n",
    "    fco2T_series = fco2T_series.assign_coords({\"time\":(\"time\",fco2D_unseen_series.time.data)})\n",
    "    fco2_unseen = fco2T_series + fco2D_unseen_series    \n",
    "    fco2_full =  fco2T_series + fco2D_full_series\n",
    "    fco2_train =  fco2T_series + fco2D_train_series\n",
    "    fco2_test =  fco2T_series + fco2D_test_series\n",
    "    \n",
    "    comp = xr.Dataset({'pco2_recon_unseen':([\"time\",\"latitude\",\"longitude\"],fco2_unseen.data),     \n",
    "                    'pco2_recon_full':([\"time\",\"latitude\",\"longitude\"],fco2_full.data),\n",
    "                      'pco2_recon_train':([\"time\",\"latitude\",\"longitude\"],fco2_train.data),\n",
    "                      'pco2_recon_test':([\"time\",\"latitude\",\"longitude\"],fco2_test.data)},\n",
    "                    coords={'time': (['time'],fco2T_series.time.values),\n",
    "                    'latitude': (['latitude'],fco2T_series.latitude.values),\n",
    "                    'longitude':(['longitude'],fco2T_series.longitude.values)})\n",
    "    \n",
    "    if fs.exists(file_out):\n",
    "        fs.rm(file_out,recursive=True)\n",
    "    \n",
    "    comp = comp.chunk({'time':100,'latitude':45,'longitude':90})\n",
    "    comp.to_zarr(file_out)\n",
    "    \n",
    "    print(f'finished with')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34baef44-aed3-4751-a3f8-9ca0d940a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_recon_fco2(regridded_members_dir, fco2_recon_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3609b5a-3264-4985-a56c-c1fc78f74fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af64a9c-6971-4e6e-b8bc-21e98589ee66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
